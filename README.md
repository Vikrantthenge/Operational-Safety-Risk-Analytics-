# âœˆï¸ Operational Safety & Risk Analytics

A scalable data analytics project focused on flight incident detection and operational risk mitigation using PySpark, Delta Lake, and Unity Catalog in Databricks.

---

## ğŸ“Œ Project Highlights

- ğŸ› ï¸ Built automated ETL pipelines processing **50,000+ rows** of flight incident data across 5+ years  
- ğŸ§  Engineered ML classification models to detect risk triggers, improving early detection by **15%**  
- ğŸ“¦ Leveraged Unity Catalog volumes for modular data storage and Delta Lake for scalable transformation  
- ğŸ“Š Validated incident distributions and delay patterns for operational insights  

---

# ğŸ§© ETL Pipeline â€“ Databricks

**[CSV: `sample_ops_data.csv`]**  
â¬‡ï¸  
**[Extract â†’ PySpark Read]**  
â¬‡ï¸  
**[Transform â†’ `incident_type` cleanup + `delay_flag` logic]**  
â¬‡ï¸  
**[Load â†’ Delta Table: `sample_ops_data_cleaned`]**



### âœˆï¸ Sample Ops ETL Pipeline Summary

- ğŸ“ **Source Volume:** `ops_data`  
- ğŸ§ª **Transformations:**  
  - Null/blank `incident_type` â†’ `"None"`  
  - `delay_flag`: `"Delayed"` if `delay_minutes` > 0, else `"On time"`  
- ğŸ§  **Format:** Delta Lake (Managed Table via `saveAsTable`)  
- ğŸ”— **Registered Table:** `etl-pipeline.default.sample_ops_data_cleaned`  
- âœ… **CSV Verified:** `sample_ops_data.csv` (50,000 rows)  
- ğŸ“Š **Incident Distribution:**  
  - Crew Shortage: 8,432  
  - Technical Fault: 8,315  
  - ATC Delay: 8,281  
  - Weather: 8,278  
  - Bird Strike: 8,402  
  - None: 8,144

---

## ğŸ“‚ Folder Structure
# Operational-Safety-Risk-Analytics-


---

## ğŸš€ How to Run

1. Upload `sample_ops_data.csv` to Unity Catalog volume `ops_data`
2. Run `ETL_Sample_Ops.ipynb` in Databricks
3. Output saved to `ops_data_cleaned` volume and registered as Delta table
4. Query using SQL or visualize in dashboards

---

## ğŸ“ Additional Assets

- ğŸ“Š [Notebook Preview](#) *(optional: link to Databricks notebook preview or screenshot)*  
- ğŸ–¼ï¸ [Incident Distribution Screenshot](#) *(optional: embed image for visual impact)*

---

## ğŸ™Œ Acknowledgments

Built with Databricks, PySpark, Delta Lake, and Unity Catalog.  
Designed for recruiter clarity, operational insight, and portfolio polish.

---

